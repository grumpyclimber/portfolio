{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fb2cee9",
   "metadata": {},
   "source": [
    "This is an updated version of my wikipedia scraper, the notebook explaining the first version can be found [here](https://github.com/grumpyclimber/portfolio/blob/main/wiki_scrape/scrape_wiki.ipynb). In essence the function takes an 'url friendly' (no spaces, just underscores) movie title and generates a search query on Wikipedia. Then scrapes the results of search results to get the url of the movie's page. Once we have the url of the actual page we can scrape some data from it.\n",
    "\n",
    "The updated version changes:\n",
    "* checking if the result description contains the word 'film' (step. 3.1.) and scraping the adequate result\n",
    "* scraping the distribution company name (step 7)\n",
    "* option of adding additional keyword to search query (default path_tail='_movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3743d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_wiki_vol2(df, path_tail='_movie', number_to_add=0):\n",
    "    # 1. Input:\n",
    "    search_query = df['title_urled'] + path_tail\n",
    "    # 2. Put the title into wikipedia search and extract the link to the first result:(it's not the first link!!!)\n",
    "    url = \"https://en.wikipedia.org/w/index.php?search=\"+search_query+\"&title=Special:Search&profile=advanced&fulltext=1&ns0=1\"\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    web_links = soup.find_all(\"a\")\n",
    "    # 3 check if search results page is empty or not - if the page has less than 43 links - it's an empty page\n",
    "    # with no results!\n",
    "    if len(web_links)>43:\n",
    "        spans = soup.find_all(\"div\", class_=\"searchresult\")\n",
    "        n = 0\n",
    "        # 3.1. check descriptions of results, we're after a result with a word 'film' in the description\n",
    "        for el in range(len(spans)):\n",
    "            if spans[el].text.find('film') != -1:\n",
    "                n=el\n",
    "                break\n",
    "        # 4. the first result of our seach query is actually the tenth link on the results page...normally\n",
    "        # but sometimes it's further down the list (that's where we add the number from step 3.1)\n",
    "        movie_path = web_links[10+n+number_to_add].get(\"href\")   \n",
    "        # 5. now lets scrape all of the infobox-labels into a list a check how long is that list:\n",
    "        response = requests.get(\"https://en.wikipedia.org\"+movie_path)\n",
    "        content = response.content\n",
    "        parser = BeautifulSoup(content, 'html.parser')\n",
    "        par_len = len(parser.find_all(\"th\", class_=\"infobox-label\"))\n",
    "        list_of_tags = parser.find_all(\"th\", class_=\"infobox-label\")\n",
    "        # 6. Loop trough infobox-labels list and find the position of 'Budget':\n",
    "        for num in range(8,par_len):        \n",
    "            tag_name = list_of_tags[num]\n",
    "            if tag_name.text == 'Budget':  \n",
    "                tag_numbers = parser.find_all(\"td\", class_=\"infobox-data\")[num]\n",
    "                cash = tag_numbers.text\n",
    "                break\n",
    "        # 6.1. If we can't find the budget:\n",
    "        else:\n",
    "            cash = None\n",
    "        # 7. same for distributor:                \n",
    "        for num in range(4,par_len):        \n",
    "            tag_name = list_of_tags[num]\n",
    "            if tag_name.text == 'Distributed by':  \n",
    "                tag_numbers = parser.find_all(\"td\", class_=\"infobox-data\")[num]\n",
    "                distributor = tag_numbers.text\n",
    "                break\n",
    "        # 7.1. If we can't find the distributor:\n",
    "        else:\n",
    "            distributor = None\n",
    "        return cash, distributor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
