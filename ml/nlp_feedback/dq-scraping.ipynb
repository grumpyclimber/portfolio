{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff3ab9e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-10T06:28:55.241624Z",
     "iopub.status.busy": "2021-12-10T06:28:55.241049Z",
     "iopub.status.idle": "2021-12-10T06:28:55.517882Z",
     "shell.execute_reply": "2021-12-10T06:28:55.517107Z",
     "shell.execute_reply.started": "2021-12-10T00:13:07.435691Z"
    },
    "papermill": {
     "duration": 0.296165,
     "end_time": "2021-12-10T06:28:55.518061",
     "exception": false,
     "start_time": "2021-12-10T06:28:55.221896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55764427",
   "metadata": {
    "papermill": {
     "duration": 0.008345,
     "end_time": "2021-12-10T06:28:55.535376",
     "exception": false,
     "start_time": "2021-12-10T06:28:55.527031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Scraping the main thread for links of all the published projects:\n",
    "[back to top](#index)\n",
    "\n",
    "We'll start with scraping the dataquests forum page for publishing projects, every thread on that page represents a different project. We're interested in the content of those threads. To get to that content, we need to obtain links to that content. So we have to scrape the guided project page containing all those threads, then scrape all the posts individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d34eada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T06:28:55.565979Z",
     "iopub.status.busy": "2021-12-10T06:28:55.565250Z",
     "iopub.status.idle": "2021-12-10T06:28:56.438893Z",
     "shell.execute_reply": "2021-12-10T06:28:56.439367Z",
     "shell.execute_reply.started": "2021-12-10T00:13:07.445161Z"
    },
    "papermill": {
     "duration": 0.895551,
     "end_time": "2021-12-10T06:28:56.439528",
     "exception": false,
     "start_time": "2021-12-10T06:28:55.543977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "url = \"https://community.dataquest.io/c/share/guided-project/55\"\n",
    "html = urlopen(url)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "list_all = soup.find_all(\"a\", class_=\"title raw-link raw-topic-link\")\n",
    "len(list_all)\n",
    "# print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c306e9df",
   "metadata": {
    "papermill": {
     "duration": 0.008644,
     "end_time": "2021-12-10T06:28:56.457408",
     "exception": false,
     "start_time": "2021-12-10T06:28:56.448764",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Trying to scrape this website leads to our first problem: the website displays only 30 threads. I've tried different path options and couldn't find a way to target the next 30 posts. So I came up with a brutal and simple solution:\n",
    "* manually scroll down to the bottom of the website (so that all posts are displayed)\n",
    "* save the website to a file\n",
    "* load the file to the notebook and keep on scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b9ae70a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T06:28:56.481184Z",
     "iopub.status.busy": "2021-12-10T06:28:56.480463Z",
     "iopub.status.idle": "2021-12-10T06:29:01.451201Z",
     "shell.execute_reply": "2021-12-10T06:29:01.451676Z",
     "shell.execute_reply.started": "2021-12-10T00:13:08.867824Z"
    },
    "papermill": {
     "duration": 4.985363,
     "end_time": "2021-12-10T06:29:01.451890",
     "exception": false,
     "start_time": "2021-12-10T06:28:56.466527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;tr&gt;&lt;th class=\"default\" data-sort-order=\"defau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;tr class=\"topic-list-item category-share-guid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;tr class=\"topic-list-item category-share-guid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;tr class=\"topic-list-item category-share-guid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;tr class=\"topic-list-item category-share-guid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  <tr><th class=\"default\" data-sort-order=\"defau...\n",
       "1  <tr class=\"topic-list-item category-share-guid...\n",
       "2  <tr class=\"topic-list-item category-share-guid...\n",
       "3  <tr class=\"topic-list-item category-share-guid...\n",
       "4  <tr class=\"topic-list-item category-share-guid..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import codecs\n",
    "# this is the file of the website, after scrolling all the way down:\n",
    "file = codecs.open(\"../input/dq-projects/projects.html\", \"r\", \"utf-8\")\n",
    "parser = BeautifulSoup(file, 'html.parser')\n",
    "list_all = parser.find_all('tr')\n",
    "series_4_df = pd.Series(list_all)\n",
    "# create a dataframe with values(title, link, etc.) extracted from the html file:\n",
    "df = pd.DataFrame(series_4_df, columns=['content'])\n",
    "df['content'] = df['content'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4fcd7f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T06:29:01.489919Z",
     "iopub.status.busy": "2021-12-10T06:29:01.488888Z",
     "iopub.status.idle": "2021-12-10T06:29:01.493399Z",
     "shell.execute_reply": "2021-12-10T06:29:01.494016Z",
     "shell.execute_reply.started": "2021-12-10T00:13:16.047938Z"
    },
    "papermill": {
     "duration": 0.032474,
     "end_time": "2021-12-10T06:29:01.494237",
     "exception": false,
     "start_time": "2021-12-10T06:29:01.461763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1445 entries, 0 to 1444\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   content  1445 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dea64ac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T06:29:01.519672Z",
     "iopub.status.busy": "2021-12-10T06:29:01.518810Z",
     "iopub.status.idle": "2021-12-10T06:29:01.522789Z",
     "shell.execute_reply": "2021-12-10T06:29:01.522343Z",
     "shell.execute_reply.started": "2021-12-10T00:13:15.970041Z"
    },
    "papermill": {
     "duration": 0.018375,
     "end_time": "2021-12-10T06:29:01.522933",
     "exception": false,
     "start_time": "2021-12-10T06:29:01.504558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<tr class=\"topic-list-item category-share-guided-project tag-257 tag-sql-fundamentals tag-257-8 has-excerpt unseen-topic ember-view\" data-topic-id=\"558357\" id=\"ember71\">\\n<td class=\"main-link clearfix\" colspan=\"\">\\n<div class=\"topic-details\">\\n<div class=\"topic-title\">\\n<span class=\"link-top-line\">\\n<a class=\"title raw-link raw-topic-link\" data-topic-id=\"558357\" href=\"https://community.dataquest.io/t/analyzing-cia-factbook-with-sql-full-project/558357\" level=\"2\" role=\"heading\"><span dir=\"ltr\">Analyzing CIA Factbook with SQL - Full Project</span></a>\\n<span class=\"topic-post-badges\">\\xa0<a class=\"badge badge-notification new-topic\" href=\"https://community.dataquest.io/t/analyzing-cia-factbook-with-sql-full-project/558357\" title=\"new topic\"></a></span>\\n</span>\\n</div>\\n<div class=\"discourse-tags\"><a class=\"discourse-tag bullet\" data-tag-name=\"257\" href=\"https://community.dataquest.io/tag/257\">257</a> <a class=\"discourse-tag bullet\" data-tag-name=\"sql-fundamentals\" href=\"https://community.dataquest.io/tag/sql-fundamentals\">sql-fundamentals</a> <a class=\"discourse-tag bullet\" data-tag-name=\"257-8\" href=\"https://community.dataquest.io/tag/257-8\">257-8</a> </div>\\n<div class=\"actions-and-meta-data\">\\n</div>\\n</div></td>\\n<td class=\"posters\">\\n<a class=\"latest single\" data-user-card=\"noah.gampe\" href=\"https://community.dataquest.io/u/noah.gampe\"><img alt=\"\" aria-label=\"noah.gampe - Original Poster, Most Recent Poster\" class=\"avatar latest single\" height=\"25\" src=\"./Latest Share_Guided Project topics - Dataquest Community_files/12175_2.png\" title=\"noah.gampe - Original Poster, Most Recent Poster\" width=\"25\"/></a>\\n</td>\\n<td class=\"num posts-map posts\" title=\"This topic has 0 replies\">\\n<button class=\"btn-link posts-map badge-posts\">\\n<span aria-label=\"This topic has 0 replies\" class=\"number\">0</span>\\n</button>\\n</td>\\n<td class=\"num likes\">\\n</td>\\n<td class=\"num views\"><span class=\"number\" title=\"this topic has been viewed 9 times\">9</span></td>\\n<td class=\"num age activity\" title=\"First post: Nov 20, 2021 9:25 am\\nPosted: Nov 20, 2021 9:27 am\">\\n<a class=\"post-activity\" href=\"https://community.dataquest.io/t/analyzing-cia-factbook-with-sql-full-project/558357/1\"><span class=\"relative-date\" data-format=\"tiny\" data-time=\"1637360860367\">1d</span></a>\\n</td>\\n</tr>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how one cell looks like:\n",
    "df.loc[2,'content'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98a9ad06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T06:29:01.561544Z",
     "iopub.status.busy": "2021-12-10T06:29:01.554841Z",
     "iopub.status.idle": "2021-12-10T06:29:01.594632Z",
     "shell.execute_reply": "2021-12-10T06:29:01.594050Z",
     "shell.execute_reply.started": "2021-12-10T00:13:15.980216Z"
    },
    "papermill": {
     "duration": 0.061911,
     "end_time": "2021-12-10T06:29:01.594778",
     "exception": false,
     "start_time": "2021-12-10T06:29:01.532867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>replies</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;tr class=\"topic-list-item category-share-guid...</td>\n",
       "      <td>Predicting house prices</td>\n",
       "      <td>https://community.dataquest.io/t/predicting-ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;tr class=\"topic-list-item category-share-guid...</td>\n",
       "      <td>[Re-upload]Project Feedback - Popular Data Sci...</td>\n",
       "      <td>https://community.dataquest.io/t/re-upload-pro...</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;tr class=\"topic-list-item category-share-guid...</td>\n",
       "      <td>GP: Clean and Analyze Employee Exit Surveys ++</td>\n",
       "      <td>https://community.dataquest.io/t/gp-clean-and-...</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;tr class=\"topic-list-item category-share-guid...</td>\n",
       "      <td>Project Feedback - Popular Data Science Questions</td>\n",
       "      <td>https://community.dataquest.io/t/project-feedb...</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;tr class=\"topic-list-item category-share-guid...</td>\n",
       "      <td>Guided Project: Answer to Albums vs. Singles w...</td>\n",
       "      <td>https://community.dataquest.io/t/guided-projec...</td>\n",
       "      <td>5</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  \\\n",
       "4   <tr class=\"topic-list-item category-share-guid...   \n",
       "5   <tr class=\"topic-list-item category-share-guid...   \n",
       "7   <tr class=\"topic-list-item category-share-guid...   \n",
       "10  <tr class=\"topic-list-item category-share-guid...   \n",
       "12  <tr class=\"topic-list-item category-share-guid...   \n",
       "\n",
       "                                                title  \\\n",
       "4                             Predicting house prices   \n",
       "5   [Re-upload]Project Feedback - Popular Data Sci...   \n",
       "7      GP: Clean and Analyze Employee Exit Surveys ++   \n",
       "10  Project Feedback - Popular Data Science Questions   \n",
       "12  Guided Project: Answer to Albums vs. Singles w...   \n",
       "\n",
       "                                                 link  replies  views  \n",
       "4   https://community.dataquest.io/t/predicting-ho...        1     26  \n",
       "5   https://community.dataquest.io/t/re-upload-pro...        3     47  \n",
       "7   https://community.dataquest.io/t/gp-clean-and-...        2     53  \n",
       "10  https://community.dataquest.io/t/project-feedb...        5     71  \n",
       "12  https://community.dataquest.io/t/guided-projec...        5    370  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[1:,:]\n",
    "# extract title, link and number of replies:\n",
    "df['title'] = df['content'].str.extract('<span dir=\"ltr\">(.*?)</span>')\n",
    "df['link'] = df['content'].str.extract('href=(.*?)level=\"2\"')\n",
    "df['link'] = df['link'].str.extract('\\\"(.*?)\\\"')\n",
    "df['replies'] = df['content'].str.extract(\"This topic has (.*?) re\").astype(int)\n",
    "df['views'] = df['content'].str.extract(\"this topic has been viewed (.*?) times\")\n",
    "df['views'] = df['views'].str.replace(',','').astype(int)\n",
    "# remove 1 generic post and posts with 0 replies:\n",
    "df = df[df['replies']>0]\n",
    "df = df[df['replies']<100]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98a87f2",
   "metadata": {
    "papermill": {
     "duration": 0.009796,
     "end_time": "2021-12-10T06:29:01.614898",
     "exception": false,
     "start_time": "2021-12-10T06:29:01.605102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Scraping the individual posts for feedback:\n",
    "\n",
    "**We've collected all the necessary links, now we can commence scraping the actual websites containing original post (published project) and replies (feedback).** We've already filtered out the posts without any replies, now we're going to assume that **only the first reply is valuable for us**. Many posts contain long discussions about various features of published projects, on average my gut feeling tells me the first post usually contains the best feedback, then the conversations, gratitude etc. start. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9629b2e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T06:29:01.642545Z",
     "iopub.status.busy": "2021-12-10T06:29:01.641603Z",
     "iopub.status.idle": "2021-12-10T06:29:02.875071Z",
     "shell.execute_reply": "2021-12-10T06:29:02.875726Z",
     "shell.execute_reply.started": "2021-12-10T00:13:16.064829Z"
    },
    "papermill": {
     "duration": 1.251086,
     "end_time": "2021-12-10T06:29:02.875989",
     "exception": false,
     "start_time": "2021-12-10T06:29:01.624903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     \\nprocessing data inside a function saves memo...\n",
       "5     \\nHi,\\nI’ve been going through your project an...\n",
       "7     \\n\\n\\nnoticed that you’re deleting objects, af...\n",
       "10            \\nthink you forgot to attach your file…\\n\n",
       "12    \\n@gdelaserre: recategorized your topic. The E...\n",
       "Name: feedback, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a function for scraping the actual posts website:\n",
    "def get_reply(one_link):\n",
    "    response = requests.get(one_link)\n",
    "    content = response.content\n",
    "    parser = BeautifulSoup(content, 'html.parser')\n",
    "    tag_numbers = parser.find_all(\"div\", class_=\"post\")\n",
    "    # we're only going to scrape the content of the first reply (that's usually the feedback)\n",
    "    feedback = tag_numbers[1].text\n",
    "    return feedback\n",
    "\n",
    "# create a test dataframe to test scraping on 5 rows:\n",
    "df_test = df[:5].copy()\n",
    "\n",
    "# we'll use a loop on all the elements of pd.Series (fastern than using 'apply')\n",
    "feedback_list = []\n",
    "for el in df_test['link']:\n",
    "    feedback_list.append(get_reply(el))\n",
    "df_test['feedback'] = feedback_list\n",
    "df_test['feedback']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13cd4b53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T06:29:02.902833Z",
     "iopub.status.busy": "2021-12-10T06:29:02.901906Z",
     "iopub.status.idle": "2021-12-10T06:29:02.906384Z",
     "shell.execute_reply": "2021-12-10T06:29:02.906939Z",
     "shell.execute_reply.started": "2021-12-10T00:13:20.493640Z"
    },
    "papermill": {
     "duration": 0.018957,
     "end_time": "2021-12-10T06:29:02.907106",
     "exception": false,
     "start_time": "2021-12-10T06:29:02.888149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprocessing data inside a function saves memory (the variables you create stay inside the function and are not stored in memory, when you’re done with the function) it’s important when you’re working with larger datasets - if you’re interested with experimenting:\\nhttps://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\\nTry cleaning 1 month of this dataset on kaggle notebook (and look at your RAM usage) outside the function and inside the function, compare the RAM usage in both examples\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['feedback'][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0e9bb",
   "metadata": {
    "papermill": {
     "duration": 0.010601,
     "end_time": "2021-12-10T06:29:02.928482",
     "exception": false,
     "start_time": "2021-12-10T06:29:02.917881",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### It works, time to try it out on a bigger fish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f71f6d6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T06:29:02.954427Z",
     "iopub.status.busy": "2021-12-10T06:29:02.953453Z",
     "iopub.status.idle": "2021-12-10T06:35:02.256982Z",
     "shell.execute_reply": "2021-12-10T06:35:02.257448Z",
     "shell.execute_reply.started": "2021-12-10T00:13:20.504273Z"
    },
    "papermill": {
     "duration": 359.317893,
     "end_time": "2021-12-10T06:35:02.257615",
     "exception": false,
     "start_time": "2021-12-10T06:29:02.939722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>replies</th>\n",
       "      <th>views</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;tr class=\"topic-list-item category-share-guid...</td>\n",
       "      <td>Predicting house prices</td>\n",
       "      <td>https://community.dataquest.io/t/predicting-ho...</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>\\nprocessing data inside a function saves memo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;tr class=\"topic-list-item category-share-guid...</td>\n",
       "      <td>[Re-upload]Project Feedback - Popular Data Sci...</td>\n",
       "      <td>https://community.dataquest.io/t/re-upload-pro...</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>\\nHi,\\nI’ve been going through your project an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;tr class=\"topic-list-item category-share-guid...</td>\n",
       "      <td>GP: Clean and Analyze Employee Exit Surveys ++</td>\n",
       "      <td>https://community.dataquest.io/t/gp-clean-and-...</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>\\n\\n\\nnoticed that you’re deleting objects, af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;tr class=\"topic-list-item category-share-guid...</td>\n",
       "      <td>Project Feedback - Popular Data Science Questions</td>\n",
       "      <td>https://community.dataquest.io/t/project-feedb...</td>\n",
       "      <td>5</td>\n",
       "      <td>71</td>\n",
       "      <td>\\nthink you forgot to attach your file…\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;tr class=\"topic-list-item category-share-guid...</td>\n",
       "      <td>Guided Project: Answer to Albums vs. Singles w...</td>\n",
       "      <td>https://community.dataquest.io/t/guided-projec...</td>\n",
       "      <td>5</td>\n",
       "      <td>370</td>\n",
       "      <td>\\n@gdelaserre: recategorized your topic. The E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content  \\\n",
       "4   <tr class=\"topic-list-item category-share-guid...   \n",
       "5   <tr class=\"topic-list-item category-share-guid...   \n",
       "7   <tr class=\"topic-list-item category-share-guid...   \n",
       "10  <tr class=\"topic-list-item category-share-guid...   \n",
       "12  <tr class=\"topic-list-item category-share-guid...   \n",
       "\n",
       "                                                title  \\\n",
       "4                             Predicting house prices   \n",
       "5   [Re-upload]Project Feedback - Popular Data Sci...   \n",
       "7      GP: Clean and Analyze Employee Exit Surveys ++   \n",
       "10  Project Feedback - Popular Data Science Questions   \n",
       "12  Guided Project: Answer to Albums vs. Singles w...   \n",
       "\n",
       "                                                 link  replies  views  \\\n",
       "4   https://community.dataquest.io/t/predicting-ho...        1     26   \n",
       "5   https://community.dataquest.io/t/re-upload-pro...        3     47   \n",
       "7   https://community.dataquest.io/t/gp-clean-and-...        2     53   \n",
       "10  https://community.dataquest.io/t/project-feedb...        5     71   \n",
       "12  https://community.dataquest.io/t/guided-projec...        5    370   \n",
       "\n",
       "                                             feedback  \n",
       "4   \\nprocessing data inside a function saves memo...  \n",
       "5   \\nHi,\\nI’ve been going through your project an...  \n",
       "7   \\n\\n\\nnoticed that you’re deleting objects, af...  \n",
       "10          \\nthink you forgot to attach your file…\\n  \n",
       "12  \\n@gdelaserre: recategorized your topic. The E...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets scrape all the posts, not just 5 of them:\n",
    "def scrape_replies(df):\n",
    "    feedback_list = []\n",
    "    for el in df['link']:\n",
    "        feedback_list.append(get_reply(el))\n",
    "    df['feedback'] = feedback_list\n",
    "    return df    \n",
    "\n",
    "df = scrape_replies(df)\n",
    "# save the file:\n",
    "df.to_csv('dq.csv',index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2af701fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-10T06:35:02.292176Z",
     "iopub.status.busy": "2021-12-10T06:35:02.291528Z",
     "iopub.status.idle": "2021-12-10T06:35:02.294308Z",
     "shell.execute_reply": "2021-12-10T06:35:02.294790Z",
     "shell.execute_reply.started": "2021-12-10T00:29:44.066828Z"
    },
    "papermill": {
     "duration": 0.026104,
     "end_time": "2021-12-10T06:35:02.294960",
     "exception": false,
     "start_time": "2021-12-10T06:35:02.268856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1102 entries, 4 to 1444\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   content   1102 non-null   object\n",
      " 1   title     1102 non-null   object\n",
      " 2   link      1102 non-null   object\n",
      " 3   replies   1102 non-null   int64 \n",
      " 4   views     1102 non-null   int64 \n",
      " 5   feedback  1102 non-null   object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 4.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage=\"deep\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 376.47526,
   "end_time": "2021-12-10T06:35:03.117225",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-10T06:28:46.641965",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
